---
title:
css: style.css
output:
  revealjs::revealjs_presentation:
    reveal_options:
      slideNumber: true
      previewLinks: true
    theme: white
    center: false
    transition: fade
    self_contained: false
    lib_dir: libs
---
##
<h2>Sampling Your Posterior</h2>

![](./images/12/coolest_bayesian.jpg){width="60%"}


```{r prep, echo=FALSE, cache=FALSE, message=FALSE, warning=FALSE}
library(knitr)
opts_chunk$set(fig.height=5, fig.width=7, comment=NA, 
               warning=FALSE, message=FALSE, 
               dev="jpeg", echo=TRUE)

library(rethinking)
library(tidyverse)
library(ggplot2)
theme_set(theme_bw(base_size = 14))
```
## The data
So, we've flipped the globe 6 times, and drawn W,L,W,W,W,L,W,L,W\
```{r define_w, echo=TRUE}
water <- 6
```

![](./images/12/rcLnp89bi.jpg){width="50%"}

## Grid Sampling
<div style="text-align:left">
In a data frame:  
1. Use `seq` to come up with a set of possible probability values\
\
2. Add a column of priors. Make it flat, so they're all 1, or get fancy.\
\
3. Calculate your likelihoods for each probability with size=9 and W=6\
\
4. Calculate your prior * likelihood\
\
5. Calculate your posterior, as the previous value divided by the sum of all prior*likelihoods
</div>

## And we've made a grid sample
```{r make_grid, echo=TRUE}
library(dplyr)

grid <- data.frame(prob = seq(0,1,.01), prior=1) %>%
  
  mutate(likelihood = 
           dbinom(water, size = 9, prob = prob)) %>%
  
  mutate(posterior = likelihood*prior) %>%
  
  mutate(posterior = posterior/sum(posterior))
```

## 
<br><br><br>
<center><h3>How do we query our posterior?</h3></centeR>

## Our posterior
```{r}
head(grid)
```

## Our posterior at it's peak
```{r}
grid %>% arrange(desc(posterior)) %>% head
```
## How do we query our posterior?
> 1. We could look at all values of the posterior and calcuate the density  
\
> 2. We could look at the highest posterior or weighted average  
\
> 3. We could integrate over a selected range and...

## AH! Intergrals? No! Samples? Yes!
> - Posteriors summarize the frequency of certain values  
\
> - We can leverage that and use our grid sample to generate an **empirical distribution**  
\
> - This lets us develop an intuitive notion of the posterior, and manipulate it easily

## Sampling from your Posterior
```{r samp}
samp <- sample(grid$prob, 
               
               size = 1e4,
               
               replace=TRUE,
               
               prob = grid$posterior)
```

## Sampling from your Posterior
```{r plot_samp, echo = TRUE}
plot(samp)
```

## Sampling from your Posterior: MCMC style
```{r ggplot_samp}
samp_df <- tibble(samp = samp, draw = 1:length(samp))
qplot(y = samp, x = draw, data = samp_df, geom="line")
```


## What can we do with this: histogram
```{r hist_samp, echo = TRUE}
qplot(x = samp, data = samp_df, geom="histogram", bins = 40)+
  ggtitle("bins = 40")
```

## Histograms can show weakness of grid
```{r hist_samp_50}
qplot(x = samp, data = samp_df, geom="histogram", bins = 50) +
  ggtitle("bins = 50")
```


## What can we do with this: density
```{r density_samp, echo = TRUE}
qplot(x = samp, data = samp_df, geom="density", fill=I("grey"))
```

## What do you learn from this?
```{r density_samp, echo = FALSE}
```

##
\
\
\
<h3>Summarizing a Parameter with a Sample</h3>

## Summarizing a sample of a posterior: Questions we can ask
> How much of the posterior is *less* than a certain value?  
\
> How much of the posterior is *greater* than a certain value?  
\
> What value of the posterior has the highest density?  
\
> What is the range of the values of some percent of the posterior? e.g., 90%  

## Looking at mass < a key value
- Let's say we wanted the % of the posterior < 0.4  
\
```{r echo = TRUE}
sum(samp < 0.4) / length(samp)
```

So, `r sum(samp < 0.4) / length(samp)*100`% of the posterior

## Plotting
It's a filter thang!
```{r plot_crit_val, eval=FALSE}
ggplot() +
  
  #grid posterior
  geom_line(data = grid,
               aes(x = prob, y = posterior)) +
  
  #the interval
  geom_ribbon(data = grid %>% filter(prob < 0.4),
              ymin = 0, aes(x = prob, ymax = posterior),
              fill = "black")
```

## Plotting
```{r plot_crit_val, echo=FALSE}
```

## Try a few
- What % is < 0.6  \
  
- What % is > 0.6  \
  
- What % is between 0.2 and 0.6  \


## How do we describe a parameter
- Typically we want to know a parameter estimate and incormation about uncertainty  
\
- Uncertainty can be summarized via the distribution of a large sample  
    - We can look at credible intervals based on mass of sample  
\
- We have a few point estimates we can also draw from a sample  
    - Mean, median, mode

## Summarizing Uncertainty: 50th Percentile Interval
<div style="text-align:left">
We often look at the 95% interval
```{r quant_95}
quantile(samp, c(0.025, 0.975))
```
<div class = "fragment">
But this is arbitrary (thanks, Fisher), and unstable. Lower intervals are more stable
</div>
<div class = "fragment">
```{r quant_50}
quantile(samp, c(0.25, 0.75))
```
</div>
</div>


## Summarizing Uncertainty: 50th Percentile Interval
We can calculate quantiles using the cummulative density of the posterior

```{r quant2}
grid <- grid %>%
  mutate(quantile = cumsum(posterior)/sum(posterior))
```

## Summarizing Uncertainty: 50th Percentile Interval
Visualize as before
```{r quant_plot, eval=FALSE}
ggplot() +
  
  #grid posterior
  geom_line(data = grid,
               aes(x = prob, y = posterior)) +
  
  #the interval
  geom_ribbon(data = grid %>% filter(quantile > 0.25 & quantile < 0.75),
              ymin = 0, aes(x = prob, ymax = posterior),
              fill = "black")
```

## Summarizing Uncertainty: 50th Percentile Interval
Visualize as before
```{r quant_plot, echo = FALSE}
```

Note that this is not the **Highest** Posterior Density Interval

## PI v. HPDI
- Percentile Intervals get interval around median that covers X% of the distribution\
\
- Highest Posteriod Density Interval gets interval with highest density containing 50% of mass of distribution
```{r HPDI_PI}
library(rethinking)
PI(samp, 0.5)
HPDI(samp, 0.5)
```

## PI v. HPDI for a Skewed Distribution
```{r bad_dist}
samp_bad <- rbeta(1e4, 2,3)

PI(samp_bad, 0.5)

HPDI(samp_bad, 0.5)
```

## PI v. HPDI
```{r hpdi_pi_plot, echo=FALSE}
par(mfrow=c(1,2))
dens <- density(samp_bad)
q25 <- quantile(samp_bad, 0.25)
q75 <- quantile(samp_bad, .75)
x1 <- min(which(dens$x >= q25))  
x2 <- max(which(dens$x <  q75))
plot(dens, main="Percentile Interval")
with(dens, polygon(x=c(x[c(x1,x1:x2,x2)]), y= c(0, y[x1:x2], 0), col="gray"))

q25h <-HPDI(samp_bad, 0.5)[1]
q75h <- HPDI(samp_bad, 0.5)[2]
x1h <- min(which(dens$x >= q25h))  
x2h <- max(which(dens$x <  q75h))
plot(dens, main="Highest Posterior Density Interval")
with(dens, polygon(x=c(x[c(x1h,x1h:x2h,x2h)]), y= c(0, y[x1h:x2h], 0), col="gray"))
par(mfrow=c(1,1))
```

## So which interval to use?
- Usually, they are quite similar\
\
- PI communicates distirbution shape for parameter\
\
- HPDI matches more with the mass of the parameter that is consistent with the data\
\
- BUT - computationally intensive and sensitive to # of posterior draws\
\
- If the two are *very* different, the problem is *not* which interval type to use\
    - It's in your model/data! Buyer beware!

## Which Point Estimate: Mean, Median, Mode?
```{r mmm}
mean(samp)

median(samp)

#mode
samp[which.max(grid$posterior)]
```

## Applying a Loss Function!
- Well, let's think about the cost of getting it wrong!  
\
- Assume a point estimate of d\
\
- The cost of being wrong if using d is:\
    $\sum{posterior * \left |(d-p)\right |}$\
\
- Could have also squared or done other things depending on cost of being wrong\
\
- Can apply this to chosing $\alpha$ and $\beta$ in frequentist stats!

## Linear Loss Function Says Median (it's close)!
```{r linear_loss}
loss_fun <- function(d) sum(grid$posterior * abs(d - grid$prob))

loss <- sapply(grid$prob, loss_fun)

grid$prob[which.min(loss)]
```

## Linear Loss Function Says Median (it's close)!
```{r}
grid$loss <- loss
ggplot(grid) +
  geom_line(aes(x = prob, y = loss)) +
  geom_point(x = grid$prob[which.min(loss)], y = min(loss),
             size = 2) +
  geom_vline(data = data.frame(value = c(mean(samp),
                                           median(samp),
                                           samp[which.max(grid$posterior)]),
                               measure = c("mean", "median", "mode")),
             aes(xintercept = value, color = measure)) +
  scale_color_manual(values = c("red", "blue", "black"))
```

## Choosing a loss function
- Usually the mean and median will agree\
\
- If the cost of being wrong is higher, go with the mean\
\
- If this is a big problem, or big discrepancy, problem might be deeper

##
\
\
\
<h3>Using your samples for model checking</h3>

## Model Checking - Why?
- We're in Simulation land\
\
- A lot can go wrong do to small errors in our model\
\
- A lot can go wrong because of big errors in our model\
\
- Maybe our software failed (i.e., convergence)\
\
- Maybe our sampling design cannot produce valid estimates

## How do you check models?
- Did you reproduce your observed summarized data?\
\
- Did you reproduce patterns in your raw data?

## Simulating from your Posterior Sample
- Make random draws using your sampled parameters

```{r make_sim}
w <- rbinom(1e4, size=9, prob = samp)
```

```{r sim_summary}
table(w)
```

## Simulating from your Posterior Sample
```{r sim_hist}
simplehist(w)
```

Note that 6 is the peak, and our draw was w=6!

## Getting Fancier with Checking
- We drew  W,L,W,W,W,L,W,L,W\
\
- Can we reproduce 3 Ws as the most common run?\
\
- This will require fancier use of the posterior to simulate order of observations\
\
- See slide code - but, this empahsized the subjective nature of model checking!

## So, reproducing runs of W
```{r runs, echo=FALSE}

getRuns <- function(prob, draws=9){
  toss <- rbinom(draws, size=1, prob)
  runs <- which(toss==0)
  if(length(runs)==0) return(9)
  #toss
  max(runs - c(1, runs[-length(runs)]+1))
}

s <- sapply(samp, getRuns)
simplehist(s)
```

We had a run of 3 - not bad, not spot on - is this a good model or check?

## Exercise
- Choose a # of observations and # of tosses that land on W  
\
- Use grid sampling to get a posterior with your choice of prior  
\
- Derive point estimates and uncertainty  
\
- Did your model checks show you were all good?

